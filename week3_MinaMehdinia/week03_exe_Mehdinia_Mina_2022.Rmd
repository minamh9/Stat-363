---
title: "In-class Exercise Week 3"
author: "Mina Mehdinia"
date: "4/14/2022"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tuesday Lecture: Permutation test for two group means

## Sleep vs Caffeine experiment

In an experiment on memory (Mednicj et al, 2008), students were given lists of 24 words to memorize. After hearing the words they were assigned at random to different groups. One group of 12 students took a nap for 1.5 hours while a second group of 12 students stayed awake and was given a caffeine pill. 

These data contain the number of words each participant was able to recall after the break:
```{r}
Memory <- read.csv("http://www.mosaic-web.org/go/datasets/SleepCaffeine.csv")
Memory
```


You want to test whether the data indicate a difference in mean number of words recalled between the two treatments.  Let's use a *permutation test* to do so.

## Interlude: Permutation Tests

In testing a null hypothesis we need a test statistic that will have different values under the *null hypothesis* (the means of the two groups are the same) and the *alternative hypothesis* we care about (i.e., the means are different).

To test the hypothesis, we need to know the sampling distribution of the test statistic when the null hypothesis is true. For some test statistics and some null hypotheses this is not possible. The p-value tells us how likely it is (under the null hypothesis) for the test statistic to be at least as extreme as the one we observed, if the null hypothesis is true.

Because of this, if the null hypothesis is true, then shuffled data sets should look like the real data, otherwise they should look different from the real data. A permutation test gives a simple way to compute the sampling distribution for any test statistic, under the null hypothesis that the treatment has absolutely no effect on the outcome, and the ranking of the real test statistic among the shuffled test statistics allows us to obtain a p-value.

From the theory, we know that the distribution of a difference in the means and we could just do a t-test.  For the t-test to be valid we need enough samples so the Central Limit Theorem kicks in. In our case, a t-test might not work since we have only a few subjects. More information on permutation tests [here](http://faculty.washington.edu/kenrice/sisg/SISG-08-06.pdf).


## Questions


1. Calculate the observed difference (Caffeine-Sleep) between the group means
```{r}
# code here
sleep =(mean(Memory$Words[Memory$Group== "Sleep"])) 
cat("Mean of sleep is = ")
print(sleep)

caffeine =(mean(Memory$Words[Memory$Group == "Caffeine"]))
cat("Mean of caffeine is = ")
print(caffeine)

ob_diff = sleep - caffeine

cat("observed difference between the group means is = ",ob_diff,sep= "" )

```


2. Create a function (call it `perm_diff`) to randomly permute the 12 *Sleep* and 12 *Caffeine* treatment labels and calculate the means for each group under this label assignment

```{r}
# code here
perm_diff <- function(){
  random_sample = sample(Memory$Group)
  sleep =(mean(Memory$Words[random_sample== "Sleep"]))
  caffeine =(mean(Memory$Words[random_sample == "Caffeine"]))
  return(sleep -caffeine)
}
perm_diff()

```


3. Use `perm_diff` to generate 10000 permutations and store the difference between the means in a vector called `diff_vector`.
```{r}
# code here
diff_vector <- sample(10000)
for(x in 1:10000){
  diff_vector[x] <- perm_diff()
}

#print(diff_vector)
```



4. Use the function `quantile` with the vector `diff_vector` to see a quick summary of the permuted differences
```{r}
# code here
quantile(diff_vector)
```


5. Plot the *sampling distribution* of the differences using the function `hist`
```{r}
# code here
hist(diff_vector)
```

6. Use the function `abline` to see where the observed difference falls in the sampling distribution you plotted above (by default `abline` is added to your last plot)

```{r}
# code here
hist(diff_vector)
abline(v=ob_diff, col = "red")
```

7. Calculate the proportion of times that the observed differences are smaller (try greater) than the ones simulated
```{r}
 mean(ob_diff<diff_vector) #smaller
 mean(ob_diff>diff_vector) #greater
```

8. State you conclusions, is there a difference between the two treatments?

Yes, there is a difference between two treatments.As we see from histogram, the red line is not close to the middle of the histogram. 

